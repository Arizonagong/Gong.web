---
title: 'Analyzing Nested Data: Comparing Multiple Approaches'
author: bgong
date: '2020-12-10'
slug: analyzing-nested-data-comparing-multiple-approaches
categories:
  - Hierchical linear model (HLM)
  - Multilevel analysis
  - R
tags:
  - lme4
  - R
subtitle: ''
summary: ''
authors: []
lastmod: '2020-12-10T15:31:33-07:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

## **1. What is Nested Data**

Not all data was created to be independent. We often find that the real world data does not meet the strict statistical pressumption that each observation should be independent and identically distributed, so called iid. In many cases, the observations sampled from a population tend to correlate each other because they belong to the same group, region, and culture. Sample data having such common and correlative trait is called nested data. 

For instance, students in the same school share a number of trait derived from the school and district features. Students in the same school or district tend to have similar socio-economic status (SES) because students are assigned to the schools based on their residential location. Also, students in the same school tend to share same teachers, school leadership, and school resource. In this account, student samples in the same schools may violate iid principle correlating with each other.

&nbsp;

## **2. Example Data Analysis**

It can be costly to ignore the nested data structure. In this post, I will show you a difference between the models considering and not considering the nested data structure.

I used international students' data file for this analysis. The students studied in foreign country through one-year study abroad program to raise intercultural understanding. I analyzed to what extent the self-efficacy level predicts or explains the level of students intercultural understanding.

###   **2.1. Explorative Data Analysis**

This is the summary of the data set. It tells us there are four variables. Intercultural_Understanding and Self-Efficacy are the continuous variables while rest of Major and Year are categorical variables.

```{r message=FALSE, warning=FALSE, include=FALSE}
# Use the following packages for the analysis
library(tidyr)
library(dplyr)
library(ggplot2)
library(ggpubr)
library(lme4)
# This is just file path in my personal computer so you need to set
# your own directory to retrieve data for the analysis
load("/Users/bgong/Documents/Career management/Job/CV development/R portfolio/Gong.web/content/post/Nested-data/Nested-data_files/Nested.RData")
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Summary of the data
summary(Studyabroad)
```

To get a more detailed sense of the data, let's check the distribution of the data with data visualization.
```{r echo=TRUE, message=FALSE, warning=FALSE}

# Scatter plot
SA <- ggscatter(Studyabroad, x = "Self_Efficacy", y = "Intercultural_Understanding",color = "#00AFBB", size = 1, alpha = 0.6, add = "reg.line", add.params = list(color = "blue", fill = "lightgray"),
   conf.int = TRUE, 
   cor.coef = TRUE ,rug = TRUE)+
border()                                         
# Marginal density plot of x (top panel) and y (right panel)
xplot <- ggdensity(Studyabroad, "Self_Efficacy", fill = "lightgray")
yplot <- ggdensity(Studyabroad, "Intercultural_Understanding", fill = "lightgray")+
rotate()
# Cleaning the plots
SA <- SA + rremove("legend")
yplot <- yplot + clean_theme() + rremove("legend") 
xplot <- xplot + clean_theme() + rremove("legend")

library(cowplot)
plot_grid(xplot, NULL, SA, yplot, ncol = 2, align = "hv", 
      rel_widths = c(2, 1), rel_heights = c(1, 2))
```

###   **2.2. Simple Linear Regression**

The easiest way to analyze this data is simple linear regression. The analysis summary indicates that the self-efficacy of the students is positively associated with the level of intercultural understanding. The coefficient estimate is 0.3914 and the p-value is significant at 0.05 level. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
Lm0<-lm(Intercultural_Understanding ~ Self_Efficacy, data =  Studyabroad)
summary(Lm0)
```

###**2.3. Alternative Analytic Methods for the Nested Data**

However, the data is stratified with other grouping variables. The data 'Studyabroad' has 'Major' variable, indicating each students belong to a certain major program. The students' intercultural understanding explained by self-efficacy may be influenced by their majors. 

We can plot the regression line in the above scatter plot, but this time I will draw two different lines for each group. The scatter plot at bellow shows students in English and non-English major have very different pattern of association. In general, the English major students' intercultural understanding is related with their self-efficacy level, while the non-English major students showed no relationship between the two. 
```{r echo=TRUE, message=FALSE, warning=FALSE}
ggscatter(Studyabroad, x = "Self_Efficacy", y = "Intercultural_Understanding", size = 0.3,
          combine = TRUE, color = "Major", palette = "jco",
          add = "reg.line", conf.int = TRUE) +
  stat_cor(aes(color = Major), method = "spearman")
```

The biggest problem of not considering nested structure of the data is underestimation of standard error of each parameter estimation. Then, this underestimation is fed into more frequent rejection of null hypothesis for the coefficient estimation. We've already seen that the simple linear regression model rejected null hypothesis above.

####**2.3.1. Solution1. Linear Regression Model with Dummy Variables on Grouping Variables**

One of the immediate solutions to handle nested data issue is adding grouping variables as dummy in the regression modeling.

New regression model bellow included 'Major', one of the grouping variables, in the modeling. Comparing with the previous simple linear regression, the standard error of Self-efficacy's coefficient increased from 0.1841 to 0.2565. And the significant test of the coefficient estimation did not reject the null hypothesis.
```{r echo=TRUE, message=FALSE, warning=FALSE}
Lm1<-lm(Intercultural_Understanding ~ Self_Efficacy + Major, data =  Studyabroad)
summary(Lm1)
```


####**2.3.2. Solution2. Hierarchical Linear Modeling (HLM) or Multilevel Modeling**

Then, at this time, I will use hierarchical linear modeling analysis with lme4 package, so that we can compare it with the previous simple linear regression model.

First, I will create a null model to calculate intraclass correlation (ICC). This number indicates the proportion of outcome variable's total variation explained by between group variation. The ICC calculation for this data is about 12%, meaning that the 12% out of the total variation of the intercultural understanding is explained by the students' major difference.
```{r echo=TRUE, message=FALSE, warning=FALSE}
library(lme4)
Lme0<-lmer(Intercultural_Understanding ~ 1+(1|Major), data=Studyabroad)
summary(Lme0)
# ICC Calculation
library(sjstats)
icc(Lme0)
```

Then, I added self-efficacy as a predictor. The summary statistics indicates that the coefficient of self-efficacy is not significant, with its increased standard error estimation. This tells us that similar to the regression model with the grouping variables as its dummy, the multilevel modeling also helps to avoid underestimation of the standard error lowering probability to reject null hypothesis.
```{r echo=TRUE, message=FALSE, warning=FALSE}
library(lmerTest)
Lme1<-lmer(Intercultural_Understanding ~ 1 + Self_Efficacy + (1+Self_Efficacy|Major), data=Studyabroad, na.action = na.exclude)
summary(Lme1)
```