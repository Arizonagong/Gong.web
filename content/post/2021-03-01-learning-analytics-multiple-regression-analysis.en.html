---
title: 'Learning Analytics: Is Underrepresented Students Group Performing Well?'
author: bgong
date: '2021-03-01'
categories:
  - R
tags:
  - Regression
slug: learning-analytics-multiple-regression-analysis
lastmod: '2021-03-01T21:01:42-07:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="learning-analytics" class="section level2">
<h2><strong>1. Learning Analytics</strong></h2>
<p>Learning analytics is a computational approach analyzing large-sized students’ learning and education data. It became pretty much popular as the online learning and digitized school administrative platforms produce an infinite stream of students’ data on a daily basis. Many higher education institutions actively seeks for learning analytics to promote data-driven decision-making and evidence-based institutional innovation, targeting to enhance students’ performance, retention, and administrative efficiency.</p>
</div>
<div id="example-data-analysis" class="section level2">
<h2><strong>2. Example Data Analysis</strong></h2>
<p>In this post, I will analyze students’ academic achievement data to see whether the underrepresented student group is performing well enough comparing with the other majority group across the time and subject area. The data was artificially and randomly created based on the preconfigured parameter distribution.</p>
<div id="explorative-data-analysis" class="section level3">
<h3><strong>2.1. Explorative Data Analysis</strong></h3>
<div id="missing-data-analysis" class="section level4">
<h4><strong>2.1.1 Missing data analysis</strong></h4>
<p>Before starting our analysis first, it is always important to check up the missing data. Although this data was artificially created so there should not be a missing data, but we need to make it a habit to check up the missing data all the time. The result at bellow figure visually represents the missing data pattern. The grey area is the missing data observation and rest of the white area is non-missing data point. The result indicate there is no serious missingness in this data set.</p>
<pre class="r"><code># Missing data examination
vis_miss(Overall_Comp, warn_large_data = FALSE)</code></pre>
<p><img src="/post/2021-03-01-learning-analytics-multiple-regression-analysis.en_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
</div>
<div id="visual-investigation-histogram" class="section level4">
<h4><strong>2.1.2 Visual Investigation: Histogram</strong></h4>
<p>UG represents Underrepresented Group with 1 and non-UG is the other majority students with 0. MATHs means the math subjects with 1 and non-math subjects with 0. In the histogram bellow, y axis means the number of student count and x axis means GPA score. The upper histogram is the students’ distribution in the non-math subject area, and the bottom histogram is that in the math subject area. The blue and red dotted line in the middle of the histogram respectively indicate the mean GPA score of UG and non-UG group students. This figure provides us a glimpse of that first there is a clear gap between UG and non-UG students across all subject areas. But it is also indicative of that the gap has been slightly narrower in the math subjects.</p>
<pre class="r"><code>### CSP vs. Non.CSP student performance mean

UG_mean&lt;-Overall_Comp %&gt;% group_by(STDNT_GROUP3,MATHs) %&gt;% 
  summarise(mean=mean(GRD_PTS_PER_UNIT)) </code></pre>
<pre><code>## `summarise()` regrouping output by &#39;STDNT_GROUP3&#39; (override with `.groups` argument)</code></pre>
<pre class="r"><code>### Histogram Visualization
  ggplot(Overall_Comp, aes(x=GRD_PTS_PER_UNIT)) +
  geom_histogram(aes(fill=STDNT_GROUP3),position=&quot;dodge&quot;, bins=40, binwidth = 0.3)+
    facet_grid(rows = vars(MATHs), labeller = label_both) +
  labs(title=&quot;GPA Distribution&quot;, x=&quot;GPA&quot;, y=&quot;Count&quot;) +
  theme_minimal() + 
  geom_vline(data=filter(UG_mean, MATHs==0), aes(xintercept=mean),
             color=c(&quot;red&quot;,&quot;blue&quot;),linetype=&quot;dashed&quot;,size=0.8) +
  geom_vline(data=filter(UG_mean, MATHs==1), aes(xintercept=mean),
             color=c(&quot;red&quot;,&quot;blue&quot;),linetype=&quot;dashed&quot;,size=0.8) +
  scale_fill_manual(name=&quot;UG&quot;,labels = c(&quot;Non-UG&quot;, &quot;UG&quot;),values = c(&quot;#FFCB05&quot;, &quot;#00274C&quot;)) +
    theme(plot.title = element_text(size=14, face=&quot;bold.italic&quot;),
          axis.title.x = element_text(size=14, face=&quot;bold&quot;),
          axis.title.y = element_text(size=14, face=&quot;bold&quot;),
          axis.text.x = element_text(size=10, face=&quot;bold&quot;),
          axis.text.y = element_text(size=10, face=&quot;bold&quot;))</code></pre>
<p><img src="/post/2021-03-01-learning-analytics-multiple-regression-analysis.en_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="visual-investigation-time-series-change" class="section level4">
<h4><strong>2.1.3 Visual Investigation: Time Series Change</strong></h4>
<p>The graph bellow shows how the average GPA score of UG and non UG students changes across the term period. It means that in the non-math courses the gap has been maintained while the gap has been continuously narrowed in the math courses. (Yey! This is a great news to raise equitable future STEM workforce.)</p>
<pre class="r"><code># Time series trend analysis
Term_TS_UG&lt;-Overall_Comp %&gt;% 
  select(TERM,Term.Descr,STDNT_GROUP3,GRD_PTS_PER_UNIT, MATHs) %&gt;% 
  group_by(TERM,Term.Descr,STDNT_GROUP3, MATHs) %&gt;% 
  summarise(mean=mean(GRD_PTS_PER_UNIT))</code></pre>
<pre><code>## `summarise()` regrouping output by &#39;TERM&#39;, &#39;Term.Descr&#39;, &#39;STDNT_GROUP3&#39; (override with `.groups` argument)</code></pre>
<pre class="r"><code>ggplot(Term_TS_UG, aes(x=TERM, y=mean, group=STDNT_GROUP3))+
  scale_x_discrete(labels = unique(Term_TS_UG$Term.Descr))+
  scale_color_manual(name=&quot;UG&quot;,labels = c(&quot;Non-UG&quot;, &quot;UG&quot;),values = c(&quot;#FFCB05&quot;, &quot;#00274C&quot;)) +
  theme_minimal() + 
  geom_smooth(method=loess,aes(color=STDNT_GROUP3), size=1) +
  facet_grid(rows = vars(MATHs), labeller = label_both) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, size=8),
        plot.title = element_text(size=14, face=&quot;bold.italic&quot;),
        axis.title.x = element_text(size=14, face=&quot;bold&quot;),
        axis.title.y = element_text(size=14, face=&quot;bold&quot;),
        axis.text.y = element_text(size=10, face=&quot;bold&quot;)) +
  labs(title=&quot;GPA Change Across Terms&quot;, x=&quot;Term&quot;, y=&quot;GPA Mean&quot;) +
  lims(y=c(2,4))</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="/post/2021-03-01-learning-analytics-multiple-regression-analysis.en_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
<div id="visual-investigation-interaction" class="section level4">
<h4><strong>2.1.4 Visual Investigation: Interaction</strong></h4>
<p>I checked the interaction effect between UG membership and taking math classes. If there is a clear interaction then we should spot line-crossing or clear trend of convergence between the two lines. Here, the result is a bit unclear. We cannot estimate whether there is an interaction or not with this picutre.</p>
<pre class="r"><code># Interaction plot between CSP membership and Physics class
ggplot(Overall_Comp, aes(x=MATHs, y=GRD_PTS_PER_UNIT, 
                         group=STDNT_GROUP3,color=STDNT_GROUP3)) +
  stat_summary(fun = mean, geom = &quot;point&quot;) +
  stat_summary(fun = mean, geom = &quot;line&quot;) +
  scale_color_manual(name=&quot;UG&quot;,labels = c(&quot;Non-UG&quot;, &quot;UG&quot;),values = c(&quot;darkred&quot;, &quot;#00274C&quot;)) +
  theme_classic2() +
  ylim(y=c(0,4))+
  labs(title=&quot;Interaction between Maths and UG&quot;, x=&quot;Maths&quot;, y=&quot;GPA Mean&quot;) +
    theme(axis.text.x = element_text(size=14, face=&quot;bold&quot;),
          plot.title = element_text(size=14, face=&quot;bold.italic&quot;),
          axis.title.x = element_text(size=14, face=&quot;bold&quot;),
          axis.title.y = element_text(size=14, face=&quot;bold&quot;),
          axis.text.y = element_text(size=14, face=&quot;bold&quot;))</code></pre>
<p><img src="/post/2021-03-01-learning-analytics-multiple-regression-analysis.en_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
</div>
</div>
<div id="linear-multiple-regression" class="section level3">
<h3><strong>2.2. Linear Multiple Regression</strong></h3>
<div id="simplistic-model" class="section level4">
<h4><strong>2.2.1 Simplistic Model</strong></h4>
<p>Then, I ran the regression. First, I made up the simplistic model, just adding UG-membership and math class as independent variables. The result shows that the UG-membership tends to be negatively associated with students’ GPA score and this relationship is statistically significant. Also, it explains that the students taking math classes tend to score less comparing with their counterparts in the other subject classes. This is also statistically significant.</p>
<pre class="r"><code>LM2&lt;-lm(GRD_PTS_PER_UNIT ~ STDNT_GROUP3 + MATHs, data=Overall_Comp)
summary(LM2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = GRD_PTS_PER_UNIT ~ STDNT_GROUP3 + MATHs, data = Overall_Comp)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.0988 -0.3988  0.2012  0.6012  1.2978 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    3.0988039  0.0008969 3454.92   &lt;2e-16 ***
## STDNT_GROUP31 -0.3280914  0.0027967 -117.31   &lt;2e-16 ***
## MATHs1        -0.0685440  0.0028988  -23.65   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9308 on 1296733 degrees of freedom
## Multiple R-squared:  0.01084,    Adjusted R-squared:  0.01084 
## F-statistic:  7106 on 2 and 1296733 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="all-possible-confounders-counted" class="section level4">
<h4><strong>2.2.2 All Possible Confounders Counted</strong></h4>
<p>Then, we added other predictors in our regression model, because sometimes the statistical significance in the basic model diminishes due to the other predictors. Although the coefficient score has been slightly decreased, still the negative association between GPA score and UG-membership, and GPA score and math class is statistically significant. Also, it indicates male students tend to score lower comparing with the female students. HSGPA means the high school GPA score and it positively associated with their university GPA score. GPAO is the GPA score in the other classes so far in the university. It shows very strong association wit the current GPA score.
However, it was revealed that there is no interaction effect between UG-membership and math classes, though it has negative coefficient. This means that underrepresented group students taking math classes do not under- nor outperform other student group.</p>
<pre class="r"><code>LM6&lt;-lm(GRD_PTS_PER_UNIT ~ STDNT_GROUP3 + MATHs + SEX + HSGPA + GPAO +
        STDNT_GROUP3:MATHs, data=Overall_Comp)
summary(LM6)</code></pre>
<pre><code>## 
## Call:
## lm(formula = GRD_PTS_PER_UNIT ~ STDNT_GROUP3 + MATHs + SEX + 
##     HSGPA + GPAO + STDNT_GROUP3:MATHs, data = Overall_Comp)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9002 -0.3140  0.1327  0.4534  3.9119 
## 
## Coefficients:
##                        Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)          -0.2396423  0.0047388 -50.570   &lt;2e-16 ***
## STDNT_GROUP31        -0.1131594  0.0024416 -46.346   &lt;2e-16 ***
## MATHs1               -0.0240013  0.0025247  -9.507   &lt;2e-16 ***
## SEXM                 -0.0206531  0.0013716 -15.058   &lt;2e-16 ***
## HSGPA                 0.0346540  0.0005522  62.761   &lt;2e-16 ***
## GPAO                  1.0003087  0.0013613 734.803   &lt;2e-16 ***
## STDNT_GROUP31:MATHs1 -0.0128971  0.0091333  -1.412    0.158    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7773 on 1296729 degrees of freedom
## Multiple R-squared:  0.3103, Adjusted R-squared:  0.3103 
## F-statistic: 9.722e+04 on 6 and 1296729 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="multicolinearity-check" class="section level4">
<h4><strong>2.2.3 Multicolinearity Check</strong></h4>
<p>Multicolinearty indicates a degree of association among the independent variables. Once the score exceeds 7 or 9, this means that the model is inefficient because it includes some redundant variables that is explained by the other independent variables. Fortunately, in this regression model, there is no multicolinearity among the independent variables.</p>
<pre class="r"><code>car::vif(LM6)</code></pre>
<pre><code>##       STDNT_GROUP3              MATHs                SEX              HSGPA 
##           1.093532           1.088315           1.008777           1.011272 
##               GPAO STDNT_GROUP3:MATHs 
##           1.030711           1.154940</code></pre>
</div>
<div id="coefficient-change-across-time" class="section level4">
<h4><strong>2.2.4 Coefficient Change Across Time</strong></h4>
<p>What if we divide the data set according to their terms and establish regression modeling for each term? Would the coefficients be the same across the time? This is just beyond multiple regression and it may request multilevel modeling, assuming each students’ score observation is embeded in each term, or we can add term as a categorical independent variable. In addition, there is a way to include interaction between the variables and the term.</p>
<p>However, this may require more complicated data preprocessing and can be felt between multiple regression here. So, I just decided to provide simple visualization giving us a glimpse of the time series change of each coefficient. In the graphes, dots mean the coefficient for each term and the vertical lines indicate confidence interval. It shows a birds eye view of the change in coefficients across the time.</p>
<p>Although it is not a rigor statistical methods to figure out coefficient change across the time, it provides us some great insight that can build up our next model. First, the students’ general GPA has been constantly improved across the terms as we can see the intercept graph. Second, the underrepresented students’ group has improved their academic performance although their score stays lower than the majority students’ group. The graph “STDNT_GROUP3” shows this upward trend very clearly. Third, the students dramatically reversed the coefficient value from negative to positive for the math class. This means that in the past students taking math classes got a lower score comparing with the students in the non-math classes, but thesedays this tendency was reversed. Fourth, the high-school GPA (HSGPA) is still a meaningful predictor of the students’ GPA in the university, but its level of association is lower than the past. Lastly, there seems to be the seasonaly trend in the students’ GPA score, as can be seen from the graphes of Intercept, SEXM, and GPAO. We can see a constant up and down between fall and winter semester. It may indicate that our mdoel has some missing independent variable in explaining the students’ academic performance.</p>
<pre class="r"><code>Stu_Dist&lt;-Overall_Comp %&gt;% 
  select(TERM, Term.Descr, MATHs, STDNT_GROUP3) %&gt;%
  group_by(TERM,Term.Descr, MATHs, STDNT_GROUP3) %&gt;%
  summarise(n=n()) %&gt;% ungroup() %&gt;%
  group_by(TERM,Term.Descr,MATHs) %&gt;% 
  mutate(prop=n/sum(n)) %&gt;%
  mutate(MATHs=as.factor(MATHs))</code></pre>
<pre><code>## `summarise()` regrouping output by &#39;TERM&#39;, &#39;Term.Descr&#39;, &#39;MATHs&#39; (override with `.groups` argument)</code></pre>
<pre class="r"><code># LM Summary by each term

LM_Summary_TERM&lt;-Overall_Comp %&gt;% 
  group_by(TERM) %&gt;%
  do(tidy(lm(GRD_PTS_PER_UNIT ~ STDNT_GROUP3 + MATHs + SEX + HSGPA + GPAO + STDNT_GROUP3:MATHs,
             data=.),conf.int = TRUE))

plot_list=list()
for(i in unique(LM_Summary_TERM$term)){
p&lt;-ggplot(filter(LM_Summary_TERM,term==i), 
       aes(x=TERM, y=estimate)) + 
  scale_x_discrete(labels = unique(Stu_Dist$Term.Descr)) +
  geom_line() +
  geom_point() +
  geom_errorbar(aes(ymax = conf.high, ymin=conf.low), width=0.2) +
  theme_bw() +
  facet_grid(rows=&quot;term&quot;) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5)) +
  geom_vline(aes(xintercept=0),
             color=c(&quot;red&quot;),linetype=&quot;dashed&quot;,size=0.8)
  plot_list[[i]]=p
}

ggarrange(plot_list[[1]],plot_list[[2]],plot_list[[3]],plot_list[[4]],
          plot_list[[5]],plot_list[[6]],plot_list[[7]],
          ncol = 2, nrow = 4)</code></pre>
<pre><code>## geom_path: Each group consists of only one observation. Do you need to adjust
## the group aesthetic?</code></pre>
<pre><code>## geom_path: Each group consists of only one observation. Do you need to adjust
## the group aesthetic?
## geom_path: Each group consists of only one observation. Do you need to adjust
## the group aesthetic?
## geom_path: Each group consists of only one observation. Do you need to adjust
## the group aesthetic?
## geom_path: Each group consists of only one observation. Do you need to adjust
## the group aesthetic?
## geom_path: Each group consists of only one observation. Do you need to adjust
## the group aesthetic?
## geom_path: Each group consists of only one observation. Do you need to adjust
## the group aesthetic?</code></pre>
<p><img src="/post/2021-03-01-learning-analytics-multiple-regression-analysis.en_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
</div>
</div>
